{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD example\n",
    "\n",
    "This notebook provide a dummy example of a map on Spark RDD, that can be used to check that parallelisation works fine on the cluster.\n",
    "\n",
    "It consist of creating an RDD with `n_partitions` partitions, and apply a map function that waits for 2 seconds for each partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries: Cluster access\n",
    "\n",
    "* Connect to cluster with \n",
    "\n",
    "```\n",
    "ssh -p 30 -L 8000:jupyter:8000 -L 8888:hue:8888 -L 8088:hue:8088 yourlogin@bigdata.ulb.ac.be\n",
    "```\n",
    "\n",
    "Note the port redirection to get access locally to JupyterHub, Hue, and Hadoop Web UI\n",
    "\n",
    "* Open JupyterHub locally by connecting to `127.0.0.1:8000`\n",
    "* Upload this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Spark session\n",
    "\n",
    "A Spark session is created by using the pyspark.sql.SparkSession object. See [here](https://spark.apache.org/docs/latest/sql-programming-guide.html#starting-point-sparksession) for the API documentation on the SparkSession Object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is needed to start a Spark session from the notebook\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=2g\\\n",
    "                                    pyspark-shell\"\n",
    "\n",
    "# For Yarn, so that Spark knows where it runs\n",
    "os.environ['HADOOP_CONF_DIR']=\"/etc/hadoop/conf\"\n",
    "# For Yarn, so Spark knows which version to use (and we want Anaconda to be used, so we have access to numpy, pandas, and so forth)\n",
    "os.environ['PYSPARK_PYTHON']=\"/etc/anaconda3/bin/python\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']=\"/etc/anaconda3/bin/python\"\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment below to recreate a Spark session with other parameters\n",
    "#spark.stop()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\",\"10\") \\\n",
    "    .appName(\"demoRDD\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "#When dealing with RDDs, we work the sparkContext object. See https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start dummy Spark jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait function\n",
    "def wait2s(x):\n",
    "    time.sleep(2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_partitions=8\n",
    "\n",
    "data=range(0,n_partitions)\n",
    "datardd=sc.parallelize(data,n_partitions)\n",
    "\n",
    "datardd.map(wait2s).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Spark UI and check parallelisation\n",
    "\n",
    "* Open Hadoop Web UI at `127.0.0.1:8088`, and click on your running Application. You should land on an URL similar to `http://127.0.0.1:8088/cluster/app/application_1523870291186_0032`\n",
    "* Change `cluster/app` to `proxy` to get to the Spark UI: `http://127.0.0.1:8088/proxy/application_1523870291186_003`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ten runs (rows), for number of executors in (1,2,5,10,20,50,100) (in columns)\n",
    "n_executors=[1,2,5,10,20,50,100]\n",
    "results_benchmark=np.zeros((10,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run benchmark with 1 executors\n",
      "Run benchmark with 2 executors\n",
      "Run benchmark with 5 executors\n",
      "Run benchmark with 10 executors\n",
      "Run benchmark with 20 executors\n",
      "Run benchmark with 50 executors\n",
      "Run benchmark with 100 executors\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(n_executors)):\n",
    "    \n",
    "    print(\"Run benchmark with \"+str(n_executors[i])+\" executors\")\n",
    "    spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\",str(n_executors[i])) \\\n",
    "    .appName(\"demoRDD\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "    sc=spark.sparkContext\n",
    "    \n",
    "    #100 partitions\n",
    "    n_partitions=100\n",
    "    data=range(0,n_partitions)\n",
    "    datardd=sc.parallelize(data,n_partitions)\n",
    "\n",
    "    for j in range(10):\n",
    "        time_start=time.time()\n",
    "        datardd.map(wait2s).collect()\n",
    "        time_end=time.time()\n",
    "        execution_time=time_end-time_start\n",
    "        results_benchmark[j,i]=execution_time\n",
    "    \n",
    "    spark.stop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_results=pd.DataFrame(results_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203.996155</td>\n",
       "      <td>102.814379</td>\n",
       "      <td>42.032716</td>\n",
       "      <td>22.165426</td>\n",
       "      <td>12.114767</td>\n",
       "      <td>6.621064</td>\n",
       "      <td>4.248616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202.446428</td>\n",
       "      <td>101.422998</td>\n",
       "      <td>40.719628</td>\n",
       "      <td>20.532905</td>\n",
       "      <td>10.455049</td>\n",
       "      <td>4.267818</td>\n",
       "      <td>2.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202.364646</td>\n",
       "      <td>101.414514</td>\n",
       "      <td>40.698062</td>\n",
       "      <td>20.445469</td>\n",
       "      <td>10.301049</td>\n",
       "      <td>4.226435</td>\n",
       "      <td>3.038877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202.412074</td>\n",
       "      <td>101.300052</td>\n",
       "      <td>40.689649</td>\n",
       "      <td>20.466142</td>\n",
       "      <td>10.302504</td>\n",
       "      <td>4.213983</td>\n",
       "      <td>2.256187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202.295379</td>\n",
       "      <td>101.282772</td>\n",
       "      <td>40.719842</td>\n",
       "      <td>20.579664</td>\n",
       "      <td>10.278221</td>\n",
       "      <td>4.649343</td>\n",
       "      <td>2.203802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202.135807</td>\n",
       "      <td>101.295359</td>\n",
       "      <td>40.626714</td>\n",
       "      <td>20.420108</td>\n",
       "      <td>10.451300</td>\n",
       "      <td>4.237480</td>\n",
       "      <td>2.251011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202.099387</td>\n",
       "      <td>101.229429</td>\n",
       "      <td>40.629570</td>\n",
       "      <td>20.397659</td>\n",
       "      <td>10.503596</td>\n",
       "      <td>4.172134</td>\n",
       "      <td>2.301781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202.123369</td>\n",
       "      <td>101.222011</td>\n",
       "      <td>40.589454</td>\n",
       "      <td>20.378247</td>\n",
       "      <td>10.340944</td>\n",
       "      <td>4.208292</td>\n",
       "      <td>2.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202.118515</td>\n",
       "      <td>101.290374</td>\n",
       "      <td>40.559077</td>\n",
       "      <td>20.389169</td>\n",
       "      <td>10.391843</td>\n",
       "      <td>4.261171</td>\n",
       "      <td>2.432999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202.078145</td>\n",
       "      <td>101.168651</td>\n",
       "      <td>40.750894</td>\n",
       "      <td>20.365695</td>\n",
       "      <td>10.275054</td>\n",
       "      <td>4.304712</td>\n",
       "      <td>2.150319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4         5         6\n",
       "0  203.996155  102.814379  42.032716  22.165426  12.114767  6.621064  4.248616\n",
       "1  202.446428  101.422998  40.719628  20.532905  10.455049  4.267818  2.257515\n",
       "2  202.364646  101.414514  40.698062  20.445469  10.301049  4.226435  3.038877\n",
       "3  202.412074  101.300052  40.689649  20.466142  10.302504  4.213983  2.256187\n",
       "4  202.295379  101.282772  40.719842  20.579664  10.278221  4.649343  2.203802\n",
       "5  202.135807  101.295359  40.626714  20.420108  10.451300  4.237480  2.251011\n",
       "6  202.099387  101.229429  40.629570  20.397659  10.503596  4.172134  2.301781\n",
       "7  202.123369  101.222011  40.589454  20.378247  10.340944  4.208292  2.296875\n",
       "8  202.118515  101.290374  40.559077  20.389169  10.391843  4.261171  2.432999\n",
       "9  202.078145  101.168651  40.750894  20.365695  10.275054  4.304712  2.150319"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_results.to_csv(\"resultsBenchmark.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalability regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(N,n,random_seed):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    np.random.seed(0)   \n",
    "\n",
    "    #Inputs and the weights of the linear combination are drawn at random\n",
    "    X=np.random.rand(N,n)\n",
    "    theta=np.random.rand(n)\n",
    "    #noise=np.random.rand(N)\n",
    "\n",
    "    Y=np.dot(X,theta)#+noise\n",
    "    Y=Y[:,np.newaxis]\n",
    "    Z=np.concatenate((X,Y),axis=1)\n",
    "\n",
    "    print(\"Number of observations :\",N)\n",
    "    print(\"Number of features :\",n)\n",
    "\n",
    "    print(\"Dimension of X :\",X.shape)\n",
    "    print(\"Dimension of theta :\",theta.shape)\n",
    "    print(\"Dimension of Y :\",Y.shape)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Time to create artificial data: \",round(end - start,2),\"seconds\")\n",
    "    \n",
    "    return (X,Y,Z,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations : 1000000\n",
      "Number of features : 100\n",
      "Dimension of X : (1000000, 100)\n",
      "Dimension of theta : (100,)\n",
      "Dimension of Y : (1000000, 1)\n",
      "Time to create artificial data:  2.79 seconds\n"
     ]
    }
   ],
   "source": [
    "#Let us generate the dataset 10M rows, 100 features\n",
    "N=1000000\n",
    "n=100\n",
    "(X,Y,Z,theta)=genData(N,n,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808000112"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=20g\\\n",
    "                                    pyspark-shell\"\n",
    "\n",
    "# For Yarn, so that Spark knows where it runs\n",
    "os.environ['HADOOP_CONF_DIR']=\"/etc/hadoop/conf\"\n",
    "# For Yarn, so Spark knows which version to use (and we want Anaconda to be used, so we have access to numpy, pandas, and so forth)\n",
    "os.environ['PYSPARK_PYTHON']=\"/etc/anaconda3/bin/python\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']=\"/etc/anaconda3/bin/python\"\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtx_xty_row(z):\n",
    "    x=np.array(z[:-1])\n",
    "    y=z[-1]\n",
    "    xtx=np.outer(x,x)\n",
    "    xty=np.dot(x,y)\n",
    "    return (xtx,xty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ten runs (rows), for number of executors in (1,2,5,10,20,50,100) (in columns)\n",
    "n_executors=[1,2,5,10,20,50,100]\n",
    "results_benchmark=np.zeros((10,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of executors :100\n",
      "Memory per executor: 2g\n",
      "Run benchmark with 100 executors\n",
      "Time to load data: 8.856817245483398 s\n",
      "1000000\n",
      "Number of executors :50\n",
      "Memory per executor: 2g\n",
      "Run benchmark with 50 executors\n",
      "Time to load data: 6.934412479400635 s\n",
      "1000000\n",
      "Number of executors :20\n",
      "Memory per executor: 2g\n",
      "Run benchmark with 20 executors\n",
      "Time to load data: 7.10111403465271 s\n",
      "1000000\n",
      "Number of executors :10\n",
      "Memory per executor: 2g\n",
      "Run benchmark with 10 executors\n",
      "Time to load data: 7.819091081619263 s\n",
      "1000000\n",
      "Number of executors :5\n",
      "Memory per executor: 2g\n",
      "Run benchmark with 5 executors\n",
      "Time to load data: 7.823525428771973 s\n",
      "1000000\n",
      "Number of executors :2\n",
      "Memory per executor: 5g\n",
      "Run benchmark with 2 executors\n",
      "Time to load data: 8.298221826553345 s\n",
      "1000000\n",
      "Number of executors :1\n",
      "Memory per executor: 10g\n",
      "Run benchmark with 1 executors\n",
      "Time to load data: 8.146310329437256 s\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "for i in [6,5,4,3,2,1,0]:#range(len(n_executors)):\n",
    "    \n",
    "    #mem_per_exec=np.min(np.round(20/n_executors[i]),2)\n",
    "    mem_per_exec=str(max([int(np.round(10/n_executors[i])),2]))+\"g\"\n",
    "    \n",
    "    print(\"Number of executors :\"+str(n_executors[i]))\n",
    "    print(\"Memory per executor: \"+str(mem_per_exec))\n",
    "    \n",
    "    #spark.stop()\n",
    "    print(\"Run benchmark with \"+str(n_executors[i])+\" executors\")\n",
    "    spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\",n_executors[i]) \\\n",
    "    .config(\"spark.executor.memory\",mem_per_exec) \\\n",
    "    .appName(\"demoRDD\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "    sc=spark.sparkContext\n",
    "    \n",
    "    time_start=time.time()\n",
    "    \n",
    "    B=400\n",
    "    Z_RDD=sc.parallelize(Z,B)#.cache()\n",
    "    \n",
    "    time_end=time.time()\n",
    "    \n",
    "    print(\"Time to load data: \"+str(time_end-time_start)+\" s\")\n",
    "    \n",
    "    print(Z_RDD.count())\n",
    "    \n",
    "    for j in range(10):\n",
    "        time_start=time.time()\n",
    "        \n",
    "        (XtX,XtY)=Z_RDD.map(xtx_xty_row)\\\n",
    "        .reduce(lambda xtx_xty0,xtx_xty1:(xtx_xty0[0]+xtx_xty1[0],xtx_xty0[1]+xtx_xty1[1]))\n",
    "\n",
    "        XtX_inverse=np.linalg.inv(XtX)\n",
    "\n",
    "        theta_hat=np.dot(XtX_inverse,XtY)\n",
    "\n",
    "        time_end=time.time()\n",
    "        \n",
    "        execution_time=time_end-time_start\n",
    "        results_benchmark[j,i]=execution_time\n",
    "    \n",
    "    spark.stop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_results=pd.DataFrame(results_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.217127</td>\n",
       "      <td>48.167062</td>\n",
       "      <td>20.048400</td>\n",
       "      <td>10.594991</td>\n",
       "      <td>6.267728</td>\n",
       "      <td>4.874828</td>\n",
       "      <td>4.970212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.237438</td>\n",
       "      <td>47.922709</td>\n",
       "      <td>19.783868</td>\n",
       "      <td>10.143557</td>\n",
       "      <td>5.708942</td>\n",
       "      <td>2.908823</td>\n",
       "      <td>3.648048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.580764</td>\n",
       "      <td>47.577099</td>\n",
       "      <td>19.632390</td>\n",
       "      <td>10.164382</td>\n",
       "      <td>5.255147</td>\n",
       "      <td>3.128972</td>\n",
       "      <td>3.616532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.616213</td>\n",
       "      <td>47.491464</td>\n",
       "      <td>19.439164</td>\n",
       "      <td>9.927299</td>\n",
       "      <td>5.256613</td>\n",
       "      <td>3.272980</td>\n",
       "      <td>3.562915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.820755</td>\n",
       "      <td>48.071952</td>\n",
       "      <td>19.507984</td>\n",
       "      <td>10.116198</td>\n",
       "      <td>5.238891</td>\n",
       "      <td>2.597770</td>\n",
       "      <td>2.630375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91.648386</td>\n",
       "      <td>47.178033</td>\n",
       "      <td>19.568926</td>\n",
       "      <td>10.130866</td>\n",
       "      <td>5.984330</td>\n",
       "      <td>3.734691</td>\n",
       "      <td>3.337098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91.736841</td>\n",
       "      <td>46.738262</td>\n",
       "      <td>19.480052</td>\n",
       "      <td>9.881360</td>\n",
       "      <td>5.326632</td>\n",
       "      <td>2.423293</td>\n",
       "      <td>3.241172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92.948940</td>\n",
       "      <td>46.719901</td>\n",
       "      <td>19.451490</td>\n",
       "      <td>10.000390</td>\n",
       "      <td>5.134878</td>\n",
       "      <td>3.343642</td>\n",
       "      <td>6.383370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91.723531</td>\n",
       "      <td>47.284382</td>\n",
       "      <td>19.739410</td>\n",
       "      <td>10.155546</td>\n",
       "      <td>5.245079</td>\n",
       "      <td>3.095833</td>\n",
       "      <td>6.369322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.498889</td>\n",
       "      <td>47.226938</td>\n",
       "      <td>19.263505</td>\n",
       "      <td>9.849107</td>\n",
       "      <td>5.332969</td>\n",
       "      <td>2.644213</td>\n",
       "      <td>3.723275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3         4         5         6\n",
       "0  94.217127  48.167062  20.048400  10.594991  6.267728  4.874828  4.970212\n",
       "1  93.237438  47.922709  19.783868  10.143557  5.708942  2.908823  3.648048\n",
       "2  93.580764  47.577099  19.632390  10.164382  5.255147  3.128972  3.616532\n",
       "3  93.616213  47.491464  19.439164   9.927299  5.256613  3.272980  3.562915\n",
       "4  92.820755  48.071952  19.507984  10.116198  5.238891  2.597770  2.630375\n",
       "5  91.648386  47.178033  19.568926  10.130866  5.984330  3.734691  3.337098\n",
       "6  91.736841  46.738262  19.480052   9.881360  5.326632  2.423293  3.241172\n",
       "7  92.948940  46.719901  19.451490  10.000390  5.134878  3.343642  6.383370\n",
       "8  91.723531  47.284382  19.739410  10.155546  5.245079  3.095833  6.369322\n",
       "9  91.498889  47.226938  19.263505   9.849107  5.332969  2.644213  3.723275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_results.to_csv(\"resultsBenchmarkRegression.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
